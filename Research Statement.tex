\let\mymarginpar\marginpar

\documentclass[10pt,twoside]{article}

%\long\def\authornote#1{%
%        \leavevmode\unskip\raisebox{-3.5pt}{\rlap{$\scriptstyle\diamond$}}%
%        \marginpar{\raggedright\hbadness=10000
%        \def\baselinestretch{0.8}\tiny
%        \it #1\par}}
%\newcommand{\ville}[1]{\authornote{NOTE TO SELF: #1}}

\marginparwidth=1cm
\marginparsep=5pt
\newcommand\ville[1]{%
    \mymarginpar{\raggedright\hbadness=10000\tiny\it #1\par}}


\usepackage{enumerate}% http://ctan.org/pkg/enumerate
\usepackage{amsmath} 
%\usepackage{times}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{fancyhdr}
\usepackage{moreverb}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{url}
\usepackage{multirow} 
\usepackage[boxed, section]{algorithm}
%\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{cite}
\usepackage{multirow} 
\usepackage{rotating}
\usepackage{geometry}
\usepackage{fix-cm}
\usepackage{subfigure}
\usepackage{natbib}



\renewcommand{\baselinestretch}{1.2}
\setlength{\topmargin}{-0.3in}
\setlength{\textwidth}{6.2in}
\setlength{\textheight}{9in}
\setlength{\oddsidemargin}{0.2in}
\setlength{\evensidemargin}{0.2in}
\raggedbottom




\allowdisplaybreaks

\newcommand{\COR}{\text{COR}}
\newcommand{\POS}{\text{POS}}
\newcommand{\UNIT}{\text{UNIT}}
\newcommand{\LIN}{\text{LIN}}
\newcommand{\SD}{\text{SD}}

\newcommand{\myN}{\hbox{N\hspace*{-.9em}I\hspace*{.4em}}}
\newcommand{\myZ}{\hbox{Z}^+}
\newcommand{\myR}{\hbox{R}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\PP}{{\bf P}}
\newcommand{\bLambda}{\boldsymbol{\lambda}}

\renewcommand{\P}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}
\newtheorem{defi}{Definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Observation}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{observation}[theorem]{Observation}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\theoremstyle{definition}
\newtheorem{example}[theorem]{Example}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}

\renewcommand{\abstractname}{}
\def\pb{\overline{p}}
\def\pt{\tilde{p}}
\def\one{{\bf 1}}

\def\bSigma{{\bf \Sigma}}
\def\bLambda{{\bf \Lambda}}
\def\blambda{\boldsymbol{\lambda}}
\def\bOmega{{\bf \Omega}}

\def\dd{{\bf d}}
\def\D{{\bf D}}
\def\v{{\bf v}}
\def\V{{\bf V}}
\def\s{{\bf s}}
\def\m{{\bf m}}
\def\r{{\bf r}}
\def\a{{\bf a}}
\def\e{{\bf e}}
\def\x{{\bf x}}
\def\q{{\bf q}}
\def\w{{\bf w}}
\def\A{{\bf A}}
\def\M{{\bf M}}
\def\X{{\bf X}}
\def\Q{{\bf Q}}
\def\L{{\bf L}}
%\def\R{{\bf R}}
\def\Z{{\bf Z}}
\def\B{{\bf B}}
\def\SS{{\bf S}}
\def\I{{\bf I}}
\def\F{{\cal F}}
\def\G{{\cal G}}
%\def\L{{\cal L}}
\def\P{{\mathbb P}}
\def\E{{\mathbb E}}
\def\Var{{\rm Var}\,}
\def\Cov{{\rm Cov}\,}
\def\Corr{{\rm Corr}\,}
\def\ee{\varepsilon}
\def\|{\, | \,}
\def\probit{p_{\rm probit}}
\def\plog{p_{\rm log}}
\def\conv{\text{conv}}
\def\cond{\text{cond}}
\def\diag{\text{diag}}
\def\vech{\text{vech}}
\def\vec{\text{vec}}
\def\Diag{\text{Diag}}
\def\diag{\text{diag}}
\def\Tr{\text{tr}}

\def\logit{{\rm logit}}

\newcommand{\myzrfunction}[1]
{\myfunction{#1}{{\myZ}}{{\myR}}}

\newcommand{\mysection}[1]
{\noindent {\bf {#1}}}
\begin{document}


\pagestyle{myheadings}
\markboth{Ville A. Satop\"a\"a}{Research Statement}
\thispagestyle{empty}

\section*{Reseach Statement}
\vspace{1em}
For the past three years I have worked on two research projects that are not only topically very different but also have disjoint sets of collaborators. Both projects are highly interdisciplinary, involve much collaboration with subject-matter experts, and investigate research problems with strong motivation in  interesting and relevant real-world data. These projects are described in the following sections, starting with my Ph.D. thesis.

 \vspace{-0.8em}
\section{Modeling, Aggregating, and Improving Predictions}  \vspace{-0.8em}
Asking multiple agents to collectively predict the value of some quantity of interest, a.k.a. \textit{prediction polling}, has become increasingly popular in the recent years, due to modern social and computer networks \citep{goel2010prediction, mellers2014psychological}.
This form of polling was the main focus of a government funded research group, called the Good Judgment Project (GJP) (\citealt{ungar2012good, mellers2014psychological}). Throughout my Ph.D. studies, I have worked with the GJP to improve prediction of international political future events deemed important by the Intelligence Advanced Research Projects Activity (IARPA). 
Being heavily funded, the GJP was able to recruit thousands of forecasters who gave hundreds of thousands of probability estimates about hundreds of events. This formed a large forecasting database that served as an ideal platform for testing hypotheses and developing new methodology. 


The main methodological challenge in prediction polling is to determine how to combine the predictions into a single consensus. In general, principled aggregation requires an assumption about the source of heterogeneity among the predictions.
In particular, it is necessary to specify how the forecasts differ from the true value of the target quantity.
 For the past several decades, potentially due to the early forms of data collection, \textit{measurement error} has been considered as the main source of heterogeneity. This approach has become the standard and is often applied in practice even when data variation is dominated  by causes besides error in measurement. For instance, assuming measurement error may be reasonable in modeling repeated estimates from a single instrument. However, it is unlikely to hold in prediction polling, where the estimates arise from multiple, often widely different sources. 

To make this more precise, our work shows both theoretically and empirically how measurement error leads to biased aggregation.
Empirically, \cite{satopaa, satopaa2014probability} find that 
simple measurement-error-based aggregates of probability forecasts, such as the average or the median, can be improved dramatically by \textit{extremizing}, that is, by shifting them systematically closer to their nearer extreme (at zero or one). Theoretically, 
\cite{satopaa2015combining}  prove that any weighted average of univariate forecasts that are consistent with different sets of information about the target quantity is necessarily under confident and hence sub-optimal. They also explain why similar problems are likely to arise for other measures of central tendency. 
 
 
These studies strongly suggest that a new source of heterogeneity is needed. In response, this Ph.D. thesis introduces a new modeling framework, called the \textit{partial information framework}, that is based on an alternative source of heterogeneity deemed more appropriate for prediction polling. The framework is extremely general and can be applied to a broad class of prediction problems.


 \vspace{-1em} \subsection{Partial Information Framework} \vspace{-0.5em}

Consider $N$ forecasters and suppose forecaster $j$ predicts $X_j$ for some (random) quantity of interest $Y$. The partial information framework assumes that the observables $Y$ and $X_j$ are measurable random variables under some common probability space $(\Omega, \F , \P)$. 
The principal $\sigma$-field $\F$ can be interpreted as all the possible information that can be known about $Y$. 
In any Bayesian setup, it is more or less tautological that
forecaster $j$ predicts $X_j = \E(Y \| \F_j)$ based on some partial \textit{information set} $\F_j \subseteq \F$. Therefore $\F_i \neq \F_j$ if $X_i \neq X_j$, and forecast heterogeneity stems purely from \textit{information diversity}.   Note, however, that if forecaster $j$ uses a simple rule, $\F_j$ may not be the full $\sigma$-field of information available to the forecaster but rather a smaller $\sigma$-field corresponding to the information used by the rule. Furthermore, if two forecasters have access to the same $\sigma$-field, they may decide to use different sub-$\sigma$-fields, leading to different predictions. 
Therefore,
information diversity does not only arise from differences in the available information, but also from how the forecasters decide to use it. 

In practice all this information is not available. Instead, information comes to the aggregator only through the predictions. Therefore the relevant aggregator under each specific instance of the framework is the \textit{revealed} aggregator $X'' := \E (Y \|
\F'')$, where $\F'' := \sigma(X_1, \dots, X_N)$ is the $\sigma$-field generated (or revealed) by the
$X_j$'s.  If $\E(Y^2) < \infty$, then among all variables measurable with respect to $\F''$, the revealed aggregator minimizes the expected quadratic loss and therefore provides a reasonable upper bound on aggregation efficiency. \cite{satopaa2015combining} show that $X''$ never reduces to a non-trivial weighted average of the forecasts, suggesting that information diversity, as a source of forecast heterogeneity, is fundamentally different from measurement error. 


The framework, as introduced above, is clearly too abstract to be applied in practice. Therefore a more practical specification within the framework is needed. The first step is to notice that, without any further assumptions, the covariance matrix $\bSigma_X$ of the $X_j$'s extends to the unknown $Y$ as follows:
\begin{align}
\Cov\left((Y, X_1, \dots, X_N)'\right) &=  \left( \begin{matrix} 
 \Var(Y)  & \diag(\bSigma_X)'  \\
\diag(\bSigma_X) & \bSigma_X \\
\end{matrix} \right), \label{cov_str}
\end{align}
where $\diag(\bSigma_X)$ denotes the diagonal of $\bSigma_X$. This covariance matrix describes the information structure among the forecasters. In particular, $\Var(Y)$ is the maximum amount of information that can be known about $Y$, $\Var(X_j)$ quantifies the amount of information used by forecaster $j$, and 
 $\Cov (X_{i} , X_{j})$ can be interpreted as the amount of information overlap between forecasters $i$ and $j$.  Therefore increased variance suggests more information and is generally deemed helpful. This stands in clear contrast with standard statistical models that often regard higher variance as increased noise. 
 
 The second step is to choose a joint distribution for the model variables $Y, X_1, \dots, X_N$.
  \cite{satopaa2015partial} provide both intuitive and technical motivations for using the multivariate Gaussian distribution with the covariance structure (\ref{cov_str}). The resulting model, known as the \textit{Gaussian partial information model}, has been extremely successful. First, \cite{satopaamodeling} use it to provide intuition on when and how much the average forecast should be extremized. Second, \cite{satopaa2015partial} estimate $\bSigma_X$ for forecasters addressing more than one related problems and apply the revealed aggregator to real-world prediction polls, involving both probability and real-valued forecasts. In both cases, they find a noticeable performance improvement over the common measurement-error-based aggregators, suggesting that  information diversity is the more important  source of forecast heterogeneity. 


 \vspace{-1em} \subsection{Future Research}  \vspace{-0.5em}
 Our work proposes an alternative to one of the core concepts in statistics, namely measurement error. 
Given the fundamental nature of this innovation, the partial information framework offers much future research, involving both theoretical and applied projects. The following enumeration only lists some of the more natural next steps. 

\begin{enumerate}[i)]
\item In the most extreme case only a set of forecasts of a single unknown outcome are available. How should the forecasts be aggregated in such a low-data setting? \cite{satopaa2015combining} suggest that any type of weighted average (or some other measure of central tendency) is a poor choice. A better alternative was discussed by \cite{satopaamodeling}. They assume that $\bSigma_X$ is compound symmetric and then combine the forecasts with the revealed aggregator under the corresponding Gaussian partial information model.  Developing a partial information aggregator that places less constraints on the joint dependence structure or has a simple form with no dependency on parameters is certainly a future research direction with potential for high impact. 

\item A promising empirical direction is the Bayesian approach. These techniques have been found superior to the likelihood-based alternatives in many applications with small or moderately sized datasets. Therefore, given that the number of forecasts in a prediction poll is typically quite small, a Bayesian approach is likely to improve the quality of the final aggregate. This would involve  developing a prior distribution for $\bSigma_{X}$ -- a problem that seems interesting in itself because the structure (\ref{cov_str}) poses known constraints on $\bSigma_{X}$ \citep{satopaa2015partial}.  

\item Most probability aggregation procedures use one probability estimate per forecaster, even though it is common for experts studying real problems to update their probability estimates over time. \cite{satopaa2014probability} advance into unexplored areas of probability aggregation by considering a dynamic context in which experts can update their beliefs at random intervals. Overall, this paper was very well received. The aggregator therein, however, is based on measurement error. Therefore, an interesting future project would be to utilize martingale theory and develop a time-series aggregator based on partial information. 

\item The partial information framework can be also applied to forecasts made by different models. This suggests many contributions in machine learning. For instance, semi-supervised learning refers to setups with a large amount of data of which only a relatively few have been labeled. Many of the commonly used ensemble techniques, such as stacking or Bayesian averaging, however, require labeled observations to combine the individual models' predictions. In the contrary, the partial information framework can aggregate these predictions without labeled data. This suggests an opportunity for better aggregation and hence overall improved prediction accuracy.

\end{enumerate}

 \vspace{-2em} \section{Public Reporting of Hospital Mortality Rates}   \vspace{-0.5em}
Medicare's Hospital Compare is a patient-oriented website
%\footnote{Visit \url{http://www.medicare.gov/hospitalcompare} for more information}
 where patients can select multiple hospitals and compare their performance related to heart attack, heart failure, pneumonia, surgery, and other conditions. Unfortunately, \cite{silber2010hospital} showed that the model used by Hospital Compare significantly under-estimates the mortality rates at hospitals that treat a small number of patients per year. For example, for acute myocardial infarction (AMI) mortality in 2008, of 4,311 U.S. hospitals, the Hospital Compare model asserted that none were worse than average and nine were better than average. This is a very surprising result because some of these hospitals treat only a few AMI cases per year, while others treat several cases each week. The medical literature \citep{gandjour2003threshold, halm2002volume, luft1987volume} has consistently indicated that after adjusting for patient risk factors, there is a higher risk of death at a low-volume hospital. Therefore, sound \textit{general advice} would
be to avoid low volume hospitals for treatment of AMI. Even though this relationship is clear in the data used by Hospital Compare, they fail to report any such pattern. 

This failure is due to Hospital Compare's efforts to stabilize the estimated mortality rates of low-volume hospitals by shrinking them towards the U.S. national average. As a part of my Ph.D. studies I have worked in close collaboration with the Center for Outcomes Research at the Children's Hospital of Philadelphia to correct this shortcoming. 
Even though our work is about methodology, it aims to call a shift in the policy paradigm for public reporting, to a more patient-centered, Bayesian perspective \citep{publicReporting, publicReporting2}.  More specifically, it considers models that more appropriately assume low-volume hospitals to be similar to other low-volume hospitals and hence stabilize their estimates by shrinking them towards the average of hospitals with similar volume and facilities. The models form a hierarchy where each subsequent model is more flexible than the previous one and has the choice of reverting back to the Hospital Compare model if the empirical data finds this appropriate. 
 None, however, do so. Instead they find a clear volume-outcome relationship where both performance and the accuracy to estimate it improve as volume increases. 
Our AMI mortality data, which are a very careful imitation of Medicare's data and consist of about 340,000 patients distributed across about 4,300 hospitals, support all of our models much more than the Hospital Compare model. In particular, our models no longer contradict general advice. 


 \vspace{-1em} \subsection{Future Research} \vspace{-0.5em}
The largely unprincipled modeling practice in public reporting offers many research opportunities. Even though our work corrects some of these aspects and lays down foundations upon which more principled public reporting can be developed, much work remains to be done. The following enumeration provides some future direction. 



\begin{enumerate}[i)]
\item Our current models mostly separate patient and hospital characteristics. However, letting the slope coefficients of the patient characteristics to change, say, linearly in the hospital characteristics, would help in explaining what kind of hospitals are good at treating what kind of patients. Furthermore, such a model could form the basis of a new publicly available website that enables patients to type in their personal information and compare performance estimates that are personalized and hence more relevant to them. 

\item Unfortunately, the Hospital Compare model has become the ``gold standard'' in many areas of public reporting.
For instance, similar modeling mistakes have been made in rankings of liver transplantation centers. The nature of liver transplantation also poses additional questions: How well are the centers matching their available livers to patients? What is their mortality rate after controlling for the quality of these livers? To the best of our knowledge, no previous research has attempted to answer these specific questions. 

\end{enumerate}


%\bibliographystyle{plain}
\bibliographystyle{apalike}
\bibliography{biblio}		% expects file "myrefs.bib"




\end{document}